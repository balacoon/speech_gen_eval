{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Zonos\n",
    "\n",
    "New TTS from Zyphra just dropped: https://huggingface.co/Zyphra/Zonos-v0.1-hybrid. Lets evaluate it.\n",
    "Skipping the step for `balacoon/speech_gen_eval_testsets` downloading, see `xtts.ipynb` for details.\n",
    "\n",
    "Setting up environment:\n",
    "```bash\n",
    "pip install torch torchaudio zonos\n",
    "# for some reason had to install from repo too\n",
    "pip install git+https://github.com/Zyphra/Zonos.git\n",
    "# had to also install espeak\n",
    "apt install -y espeak-ng\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "#model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-hybrid\", device=\"cuda\")\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=\"cuda\")\n",
    "\n",
    "# run the synthesis for the vctk\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    mapping = {}\n",
    "    out_dir = os.path.join(\"zonos\", fold, \"wav\")\n",
    "    ref_dir = os.path.join(\"speech_gen_eval_testsets\", fold, \"wav\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    with open(os.path.join(\"speech_gen_eval_testsets\", fold, \"id_mapping\"), \"r\") as fp:\n",
    "        for line in fp:\n",
    "            k, v = line.strip().split()\n",
    "            mapping[k] = v\n",
    "    with open(os.path.join(\"speech_gen_eval_testsets\", fold, \"test\"), \"r\") as fp:\n",
    "        for line in tqdm.tqdm(fp):\n",
    "            id, txt = line.strip().split(\"\\t\", 1)\n",
    "            out_path = os.path.join(out_dir, id + \".wav\")\n",
    "            if os.path.exists(out_path):\n",
    "                continue\n",
    "\n",
    "            ref_path = os.path.join(ref_dir, mapping[id] + \".wav\")\n",
    "            wav, sampling_rate = torchaudio.load(ref_path)\n",
    "            speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
    "            cond_dict = make_cond_dict(text=txt, speaker=speaker, language=\"en-us\")\n",
    "            conditioning = model.prepare_conditioning(cond_dict)\n",
    "            codes = model.generate(conditioning)\n",
    "            wavs = model.autoencoder.decode(codes).cpu()\n",
    "            torchaudio.save(out_path, wavs[0], model.autoencoder.sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally run evaluation with `speech_gen_eval`\n",
    "import os\n",
    "from speech_gen_eval.evaluation import speech_gen_eval\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    print(f\"Evaluating {fold}\")\n",
    "    txt_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"test\")\n",
    "    generated_audio = os.path.join(\"zonos\", fold, \"wav\")\n",
    "    original_audio = os.path.join(\"speech_gen_eval_testsets\", fold, \"wav\")\n",
    "    id_mapping = os.path.join(\"speech_gen_eval_testsets\", fold, \"id_mapping\")\n",
    "    speech_gen_eval(\n",
    "        txt_path=txt_path,\n",
    "        generated_audio=generated_audio,\n",
    "        eval_type=\"zero-tts\",\n",
    "        original_audio=original_audio,\n",
    "        mapping_path=id_mapping,\n",
    "        out_path=os.path.join(\"zonos\", fold, \"metrics.yaml\"),\n",
    "        ignore_missing=True,\n",
    "        # extra arguments to write into the metrics.yaml as meta info\n",
    "        model_name=\"Zonos-v0.1-transformer\",\n",
    "        dataset=f\"balacoon/speech_gen_eval_testsets/{fold}\",\n",
    "        link=\"https://huggingface.co/Zyphra/Zonos-v0.1-transformer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after checking that evaluation succeeded, remove files that are not meant to be kept\n",
    "# dont upload all the files from test (2k),\n",
    "# but only those (150) that are meant to be kept for listening / subjective evaluation\n",
    "import os\n",
    "import glob\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Read keep file and get IDs\n",
    "    keep_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"keep\")\n",
    "    with open(keep_path) as f:\n",
    "        keep_lines = f.readlines()\n",
    "    keep_ids = set([line.split()[0] for line in keep_lines])\n",
    "    \n",
    "    for wav_file in glob.glob(os.path.join(\"zonos\", fold, \"wav\", \"*.wav\")):\n",
    "        if os.path.basename(wav_file).split(\".\")[0] not in keep_ids:\n",
    "            os.remove(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload synthetic audio and metrics to `speech_gen_baselines`,\n",
    "# so it is available on TTSLeaderboard\n",
    "\n",
    "local_dataset = \"zonos\"\n",
    "hf_dataset = \"balacoon/speech_gen_baselines\"\n",
    "hf_subdir = \"zero-tts/zonos\"\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "# Upload each fold to the appropriate subdirectory\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Upload wav files\n",
    "    api.upload_folder(\n",
    "        folder_path=os.path.join(local_dataset, fold),\n",
    "        repo_id=hf_dataset,\n",
    "        repo_type=\"dataset\",\n",
    "        path_in_repo=os.path.join(hf_subdir, fold)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zonos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
