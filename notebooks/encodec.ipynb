{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate EnCodec\n",
    "\n",
    "Evaluate original codec from meta: https://huggingface.co/facebook/encodec_24khz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EncodecModel, AutoProcessor\n",
    "\n",
    "model = EncodecModel.from_pretrained(\"facebook/encodec_24khz\")\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import resampy\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# do analysis synthesis of the single file\n",
    "wav_path = os.path.join(\"speech_gen_eval_testsets\", \"vctk\", \"wav\", \"p225_011.wav\")\n",
    "arr, sr = sf.read(wav_path, dtype=\"float32\")\n",
    "new_arr = resampy.resample(arr, sr, 24000)\n",
    "display(Audio(new_arr, rate=24000))\n",
    "inputs = processor(raw_audio=new_arr, sampling_rate=24000, return_tensors=\"pt\")\n",
    "# use all 8 books\n",
    "encoder_outputs = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"], bandwidth=6.0)\n",
    "plt.imshow(encoder_outputs.audio_codes[0][0].detach().numpy(), aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "audio_values = model.decode(encoder_outputs.audio_codes, encoder_outputs.audio_scales, inputs[\"padding_mask\"])[0]\n",
    "display(Audio(audio_values[0][0].detach().numpy(), rate=24000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import soundfile as sf\n",
    "\n",
    "# for testsets do analysis synthesis and save files to a directory for evaluation\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "out_dir = \"encodec\"\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    out_fold_dir = os.path.join(out_dir, fold, \"wav\")\n",
    "    os.makedirs(out_fold_dir, exist_ok=True)\n",
    "    with open(os.path.join(\"speech_gen_eval_testsets\", fold, \"test\"), \"r\") as fp:\n",
    "        for line in tqdm.tqdm(fp):\n",
    "            id, txt = line.strip().split(\"\\t\", 1)\n",
    "            out_path = os.path.join(out_fold_dir, id + \".wav\")\n",
    "            if os.path.exists(out_path):\n",
    "                continue\n",
    "            in_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"wav\", id + \".wav\")\n",
    "\n",
    "            arr, sr = sf.read(in_path, dtype=\"float32\")\n",
    "            new_arr = resampy.resample(arr, sr, 24000)\n",
    "            inputs = processor(raw_audio=new_arr, sampling_rate=24000, return_tensors=\"pt\")\n",
    "            encoder_outputs = model.encode(inputs[\"input_values\"].cuda(), inputs[\"padding_mask\"].cuda(), bandwidth=6.0)\n",
    "            audio_values = model.decode(\n",
    "                encoder_outputs.audio_codes, encoder_outputs.audio_scales, inputs[\"padding_mask\"]\n",
    "            )[0][0][0].detach().cpu().numpy()\n",
    "            sf.write(out_path, audio_values, 24000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally run evaluation with `speech_gen_eval`\n",
    "import os\n",
    "from speech_gen_eval.evaluation import speech_gen_eval\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    print(f\"Evaluating {fold}\")\n",
    "    txt_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"test\")\n",
    "    generated_audio = os.path.join(\"encodec\", fold, \"wav\")\n",
    "    original_audio = os.path.join(\"speech_gen_eval_testsets\", fold, \"wav\")\n",
    "    speech_gen_eval(\n",
    "        txt_path=txt_path,\n",
    "        generated_audio=generated_audio,\n",
    "        eval_type=\"vocoder\",\n",
    "        original_audio=original_audio,\n",
    "        out_path=os.path.join(\"encodec\", fold, \"metrics.yaml\"),\n",
    "        ignore_missing=True,\n",
    "        # extra arguments to write into the metrics.yaml as meta info\n",
    "        model_name=\"EnCodec (8books)\",\n",
    "        dataset=f\"balacoon/speech_gen_eval_testsets/{fold}\",\n",
    "        link=\"https://huggingface.co/facebook/encodec_24khz\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont upload all the files from test (2k),\n",
    "# but only those (150) that are meant to be kept for listening / subjective evaluation\n",
    "import os\n",
    "import glob\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Read keep file and get IDs\n",
    "    keep_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"keep\")\n",
    "    with open(keep_path) as f:\n",
    "        keep_lines = f.readlines()\n",
    "    keep_ids = set([line.split()[0] for line in keep_lines])\n",
    "    \n",
    "    for wav_file in glob.glob(os.path.join(\"encodec\", fold, \"wav\", \"*.wav\")):\n",
    "        if os.path.basename(wav_file).split(\".\")[0] not in keep_ids:\n",
    "            os.remove(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload synthetic audio and metrics to `speech_gen_baselines`,\n",
    "# so it is available on TTSLeaderboard\n",
    "\n",
    "local_dataset = \"encodec\"\n",
    "hf_dataset = \"balacoon/speech_gen_baselines\"\n",
    "hf_subdir = \"vocoder/encodec\"\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "# Upload each fold to the appropriate subdirectory\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Upload wav files\n",
    "    api.upload_folder(\n",
    "        folder_path=os.path.join(local_dataset, fold),\n",
    "        repo_id=hf_dataset,\n",
    "        repo_type=\"dataset\",\n",
    "        path_in_repo=os.path.join(hf_subdir, fold)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_gen_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
