{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lina codec\n",
    "\n",
    "[Lina codec](https://github.com/ysharma3501/LinaCodec) is a low bitrate (12.5Hz) codec. It also has a voice conversion capabilities via a global speaker embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to download the testset, git is the most straightforward way\n",
    "!git clone https://huggingface.co/datasets/balacoon/speech_gen_eval_testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"outputs/lina\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we check performance of Lina as codec, i.e. just try to do reconstruction\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from linacodec.codec import LinaCodec\n",
    "\n",
    "lina_tokenizer = LinaCodec()\n",
    "\n",
    "os.makedirs(\"outputs/lina/reconstruction\", exist_ok=True)\n",
    "for testset in [\"vctk\", \"daps_celeb\"]:\n",
    "    os.makedirs(f\"outputs/lina/reconstruction/{testset}/wav\", exist_ok=True)\n",
    "    for wav_path in tqdm.tqdm(glob.glob(f\"speech_gen_eval_testsets/{testset}/wav/*.wav\")):\n",
    "        speech_tokens, global_embedding = lina_tokenizer.encode(wav_path)\n",
    "        audio = lina_tokenizer.decode(speech_tokens, global_embedding)\n",
    "        name = os.path.splitext(os.path.basename(wav_path))[0]\n",
    "        out_path = f\"outputs/lina/reconstruction/{testset}/wav/{name}.wav\"\n",
    "        audio_numpy = audio.cpu().numpy().squeeze()\n",
    "        sf.write(out_path, audio_numpy, 48000, subtype=\"PCM_16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation of reconstruction with lina\n",
    "import os\n",
    "from speech_gen_eval.evaluation import speech_gen_eval\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    print(f\"Evaluating {fold}\")\n",
    "    txt_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"test\")\n",
    "    generated_audio = f\"outputs/lina/reconstruction/{fold}/wav\"\n",
    "    original_audio = os.path.join(\"speech_gen_eval_testsets\", fold, \"wav\")\n",
    "    speech_gen_eval(\n",
    "        txt_path=txt_path,\n",
    "        generated_audio=generated_audio,\n",
    "        eval_type=\"vocoder\",\n",
    "        original_audio=original_audio,\n",
    "        out_path=os.path.join(\"outputs\", \"lina\", \"reconstruction\", fold, \"metrics.yaml\"),\n",
    "        ignore_missing=True,\n",
    "        # extra arguments to write into the metrics.yaml as meta info\n",
    "        model_name=\"Lina codec\",\n",
    "        dataset=f\"balacoon/speech_gen_eval_testsets/{fold}\",\n",
    "        link=\"https://github.com/ysharma3501/LinaCodec\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont upload all the files from test (2k),\n",
    "# but only those (150) that are meant to be kept for listening / subjective evaluation\n",
    "import os\n",
    "import glob\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Read keep file and get IDs\n",
    "    keep_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"keep\")\n",
    "    with open(keep_path, encoding=\"utf-8\") as f:\n",
    "        keep_lines = f.readlines()\n",
    "    keep_ids = set([line.split()[0] for line in keep_lines])\n",
    "    \n",
    "    for wav_file in glob.glob(os.path.join(\"outputs\", \"lina\", \"reconstruction\", fold, \"wav\", \"*.wav\")):\n",
    "        if os.path.basename(wav_file).split(\".\")[0] not in keep_ids:\n",
    "            os.remove(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload synthetic audio and metrics to `speech_gen_baselines`,\n",
    "# so it is available on TTSLeaderboard\n",
    "\n",
    "local_dataset = \"outputs/lina/reconstruction\"\n",
    "hf_dataset = \"balacoon/speech_gen_baselines\"\n",
    "hf_subdir = \"vocoder/lina\"\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "# Upload each fold to the appropriate subdirectory\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Upload wav files\n",
    "    api.upload_folder(\n",
    "        folder_path=os.path.join(local_dataset, fold),\n",
    "        repo_id=hf_dataset,\n",
    "        repo_type=\"dataset\",\n",
    "        path_in_repo=os.path.join(hf_subdir, fold)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we check performance of Lina as voice conversion system\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from linacodec.codec import LinaCodec\n",
    "\n",
    "lina_tokenizer = LinaCodec()\n",
    "\n",
    "os.makedirs(\"outputs/lina/voice_conversion\", exist_ok=True)\n",
    "for testset in [\"vctk\", \"daps_celeb\"]:\n",
    "    # read id mapping\n",
    "    with open(f\"speech_gen_eval_testsets/{testset}/id_mapping\") as fp:\n",
    "        target2ref = {}\n",
    "        for line in fp:\n",
    "            target, ref = line.strip().split()\n",
    "            target2ref[target] = ref\n",
    "    # create output dir\n",
    "    os.makedirs(f\"outputs/lina/voice_conversion/{testset}/wav\", exist_ok=True)\n",
    "    with open(f\"speech_gen_eval_testsets/{testset}/test\") as fp:\n",
    "        for line in fp:\n",
    "            name = line.strip().split()[0]\n",
    "            orig_path = f\"speech_gen_eval_testsets/{testset}/wav/{name}.wav\"\n",
    "            ref_name = target2ref[name]\n",
    "            if not ref_name:\n",
    "                continue\n",
    "            ref_path = f\"speech_gen_eval_testsets/{testset}/wav/{ref_name}.wav\"\n",
    "            if not os.path.isfile(ref_path) or not os.path.isfile(orig_path):\n",
    "                continue\n",
    "            audio = lina_tokenizer.convert_voice(orig_path, ref_path)\n",
    "   \n",
    "            out_path = f\"outputs/lina/voice_conversion/{testset}/wav/{name}.wav\"\n",
    "            audio_numpy = audio.cpu().numpy().squeeze()\n",
    "            sf.write(out_path, audio_numpy, 48000, subtype=\"PCM_16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation of reconstruction with lina\n",
    "import os\n",
    "from speech_gen_eval.evaluation import speech_gen_eval\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    print(f\"Evaluating {fold}\")\n",
    "    txt_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"test\")\n",
    "    generated_audio = f\"outputs/lina/voice_conversion/{fold}/wav\"\n",
    "    original_audio = os.path.join(\"speech_gen_eval_testsets\", fold, \"wav\")\n",
    "    id_mapping = os.path.join(\"speech_gen_eval_testsets\", fold, \"id_mapping\")\n",
    "    speech_gen_eval(\n",
    "        txt_path=txt_path,\n",
    "        generated_audio=generated_audio,\n",
    "        eval_type=\"zero-vc\",\n",
    "        original_audio=original_audio,\n",
    "        mapping_path=id_mapping,\n",
    "        out_path=os.path.join(\"outputs\", \"lina\", \"voice_conversion\", fold, \"metrics.yaml\"),\n",
    "        ignore_missing=True,\n",
    "        # extra arguments to write into the metrics.yaml as meta info\n",
    "        model_name=\"Lina codec\",\n",
    "        dataset=f\"balacoon/speech_gen_eval_testsets/{fold}\",\n",
    "        link=\"https://github.com/ysharma3501/LinaCodec\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont upload all the files from test (2k),\n",
    "# but only those (150) that are meant to be kept for listening / subjective evaluation\n",
    "import os\n",
    "import glob\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Read keep file and get IDs\n",
    "    keep_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"keep\")\n",
    "    with open(keep_path, encoding=\"utf-8\") as f:\n",
    "        keep_lines = f.readlines()\n",
    "    keep_ids = set([line.split()[0] for line in keep_lines])\n",
    "    \n",
    "    for wav_file in glob.glob(os.path.join(\"outputs\", \"lina\", \"voice_conversion\", fold, \"wav\", \"*.wav\")):\n",
    "        if os.path.basename(wav_file).split(\".\")[0] not in keep_ids:\n",
    "            os.remove(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload synthetic audio and metrics to `speech_gen_baselines`,\n",
    "# so it is available on TTSLeaderboard\n",
    "\n",
    "local_dataset = \"outputs/lina/voice_conversion\"\n",
    "hf_dataset = \"balacoon/speech_gen_baselines\"\n",
    "hf_subdir = \"zero-vc/lina\"\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "# Upload each fold to the appropriate subdirectory\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Upload wav files\n",
    "    api.upload_folder(\n",
    "        folder_path=os.path.join(local_dataset, fold),\n",
    "        repo_id=hf_dataset,\n",
    "        repo_type=\"dataset\",\n",
    "        path_in_repo=os.path.join(hf_subdir, fold)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_gen_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
