{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balacoon Vocoder\n",
    "\n",
    "Our inhouse discrete audio codec.\n",
    "24khz, 50 frames per second, 4 codebooks.\n",
    "Middle ground between high bitrate of EnCodec and low bitrate Mimi (12.5 frames per second only) or WaveTokenizer (single codebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import soundfile as sf\n",
    "import resampy\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pylab as plt\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device('cuda')\n",
    "\n",
    "wav_path = os.path.join(\"speech_gen_eval_testsets\", \"vctk\", \"wav\", \"p225_011.wav\")\n",
    "wav16khz, sr = sf.read(wav_path, dtype=\"int16\")\n",
    "wav24khz = resampy.resample(wav16khz, sr, 24000)\n",
    "print(wav24khz.shape)\n",
    "display(Audio(wav24khz, rate=24000))\n",
    "x = torch.tensor(wav24khz).to(device).unsqueeze(0)\n",
    "\n",
    "encoder_path = hf_hub_download(repo_id=\"balacoon/vq4_50fps_24khz_vocoder\", filename=\"analysis.jit\")\n",
    "decoder_path = hf_hub_download(repo_id=\"balacoon/vq4_50fps_24khz_vocoder\", filename=\"synthesis.jit\")\n",
    "encoder = torch.jit.load(encoder_path)\n",
    "decoder = torch.jit.load(decoder_path)\n",
    "\n",
    "tokens = encoder(x)\n",
    "print(tokens.shape)\n",
    "plt.imshow(tokens[0].detach().cpu().numpy().T, aspect=\"auto\")\n",
    "plt.show()\n",
    "\n",
    "res = decoder(tokens)\n",
    "print(res.shape)\n",
    "display(Audio(res[0].detach().cpu().numpy(), rate=24000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont upload all the files from test (2k),\n",
    "# but only those (150) that are meant to be kept for listening / subjective evaluation\n",
    "import os\n",
    "import glob\n",
    "\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Read keep file and get IDs\n",
    "    keep_path = os.path.join(\"speech_gen_eval_testsets\", fold, \"keep\")\n",
    "    with open(keep_path, encoding=\"utf-8\") as f:\n",
    "        keep_lines = f.readlines()\n",
    "    keep_ids = set([line.split()[0] for line in keep_lines])\n",
    "    \n",
    "    for wav_file in glob.glob(os.path.join(\"vq4_50fps_24khz_vocoder\", fold, \"wav\", \"*.wav\")):\n",
    "        if os.path.basename(wav_file).split(\".\")[0] not in keep_ids:\n",
    "            os.remove(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload synthetic audio and metrics to `speech_gen_baselines`,\n",
    "# so it is available on TTSLeaderboard\n",
    "\n",
    "local_dataset = \"vq4_50fps_24khz_vocoder\"\n",
    "hf_dataset = \"balacoon/speech_gen_baselines\"\n",
    "hf_subdir = \"vocoder/balacoon\"\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "# Upload each fold to the appropriate subdirectory\n",
    "for fold in [\"vctk\", \"daps_celeb\"]:\n",
    "    # Upload wav files\n",
    "    api.upload_folder(\n",
    "        folder_path=os.path.join(local_dataset, fold),\n",
    "        repo_id=hf_dataset,\n",
    "        repo_type=\"dataset\",\n",
    "        path_in_repo=os.path.join(hf_subdir, fold)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_gen_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
